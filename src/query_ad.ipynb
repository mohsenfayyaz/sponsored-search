{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import autoreload\n",
    "# %load_ext autoreload\n",
    "# %aimport Trainer\n",
    "# %autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Negative Sampling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.Preprocess.Preprocessor import Preprocessor\n",
    "# Preprocessor.create_negative_sampled_dataset(input_address=\"../data/SA_history_clicks_of_98.csv\", \n",
    "#                                                output_address=\"../data/data1.pkl\", \n",
    "#                                                neg_to_pos_ratio=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DatasetHandler\n",
    "Preparing dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Reading input file...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3932f23ed0549b1ad88a8b9df4454a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Labeling Packages', max=72324.0, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e8de2a72a745bc9cc6dec8c6bb87aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=548.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9960ab993bbb4def9942cc5b2e2ea25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=137.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1883c0ab3494b01943d2b9850955758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17516.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afbf623ab374d238e30ecd859f47136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4380.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from DatasetHandler import DatasetHandler\n",
    "\n",
    "# dataset_handler = DatasetHandler(\"data/SA_history_clicks_of_98.csv\")\n",
    "dataset_handler = DatasetHandler(\"../data/small1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['__index_level_0__', 'attention_mask', 'input_ids', 'packageName', 'package_ids', 'queryText', 'similar', 'token_type_ids'],\n",
      "        num_rows: 17516\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['__index_level_0__', 'attention_mask', 'input_ids', 'packageName', 'package_ids', 'queryText', 'similar', 'token_type_ids'],\n",
      "        num_rows: 4380\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>packageName</th>\n",
       "      <th>package_ids</th>\n",
       "      <th>queryText</th>\n",
       "      <th>similar</th>\n",
       "      <th>token_type_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20558</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[2, 18183, 2469, 4, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>ir.zahuz.mahii</td>\n",
       "      <td>[161386]</td>\n",
       "      <td>پابجی</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17939</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[2, 32605, 4, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>ir.mighatenoor.sahifesorkh</td>\n",
       "      <td>[121945]</td>\n",
       "      <td>دایناسور</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1957</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[2, 16865, 35286, 2156, 4, 0, 0, 0, 0, 0]</td>\n",
       "      <td>ir.seer.resale</td>\n",
       "      <td>[141578]</td>\n",
       "      <td>رساله خامنه ای</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12665</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[2, 11271, 25536, 2067, 9182, 4, 0, 0, 0, 0]</td>\n",
       "      <td>videoconverter.farhadkargaran.gmail.com.easyvi...</td>\n",
       "      <td>[139679]</td>\n",
       "      <td>منج ومارو پله</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10265</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[2, 37947, 4, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>com.kparmun.ballz</td>\n",
       "      <td>[164108]</td>\n",
       "      <td>bmi</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>74</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 4556, 73651, 331, 10162, 4, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>com.picdastan.ini</td>\n",
       "      <td>[137729]</td>\n",
       "      <td>داستان السا و انا</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>16884</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 24009, 9927, 20307, 4701, 1173, 1198, 2729...</td>\n",
       "      <td>com.dpa_me.tvquiz</td>\n",
       "      <td>[104143]</td>\n",
       "      <td>حنامخااعبلخعلابفعختربعه 7 حنکدرله 6788 حتدددلل...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>7700</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 13543, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>com.gsg.Bruce_Lee_S01_E04</td>\n",
       "      <td>[151276]</td>\n",
       "      <td>رزمی</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>12064</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 12371, 2397, 4064, 4434, 2110, 4, 0, 0, 0,...</td>\n",
       "      <td>ir.ipm.Tvt</td>\n",
       "      <td>[149864]</td>\n",
       "      <td>قوقل بروز رسانی شده</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>687</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 45336, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>ir.khoraki.korosh</td>\n",
       "      <td>[124205]</td>\n",
       "      <td>hyper 24</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     __index_level_0__                                     attention_mask  \\\n",
       "0                20558                     [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]   \n",
       "1                17939                     [1, 1, 1, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2                 1957                     [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]   \n",
       "3                12665                     [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]   \n",
       "4                10265                     [1, 1, 1, 0, 0, 0, 0, 0, 0, 0]   \n",
       "..                 ...                                                ...   \n",
       "995                 74  [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "996              16884  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "997               7700  [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "998              12064  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "999                687  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                             input_ids  \\\n",
       "0                [2, 18183, 2469, 4, 0, 0, 0, 0, 0, 0]   \n",
       "1                   [2, 32605, 4, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2            [2, 16865, 35286, 2156, 4, 0, 0, 0, 0, 0]   \n",
       "3         [2, 11271, 25536, 2067, 9182, 4, 0, 0, 0, 0]   \n",
       "4                   [2, 37947, 4, 0, 0, 0, 0, 0, 0, 0]   \n",
       "..                                                 ...   \n",
       "995  [2, 4556, 73651, 331, 10162, 4, 0, 0, 0, 0, 0,...   \n",
       "996  [2, 24009, 9927, 20307, 4701, 1173, 1198, 2729...   \n",
       "997  [2, 13543, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "998  [2, 12371, 2397, 4064, 4434, 2110, 4, 0, 0, 0,...   \n",
       "999  [2, 45336, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                           packageName package_ids  \\\n",
       "0                                       ir.zahuz.mahii    [161386]   \n",
       "1                           ir.mighatenoor.sahifesorkh    [121945]   \n",
       "2                                       ir.seer.resale    [141578]   \n",
       "3    videoconverter.farhadkargaran.gmail.com.easyvi...    [139679]   \n",
       "4                                    com.kparmun.ballz    [164108]   \n",
       "..                                                 ...         ...   \n",
       "995                                  com.picdastan.ini    [137729]   \n",
       "996                                  com.dpa_me.tvquiz    [104143]   \n",
       "997                          com.gsg.Bruce_Lee_S01_E04    [151276]   \n",
       "998                                         ir.ipm.Tvt    [149864]   \n",
       "999                                  ir.khoraki.korosh    [124205]   \n",
       "\n",
       "                                             queryText  similar  \\\n",
       "0                                                پابجی       -1   \n",
       "1                                             دایناسور       -1   \n",
       "2                                       رساله خامنه ای        1   \n",
       "3                                        منج ومارو پله       -1   \n",
       "4                                                  bmi       -1   \n",
       "..                                                 ...      ...   \n",
       "995                                  داستان السا و انا        1   \n",
       "996  حنامخااعبلخعلابفعختربعه 7 حنکدرله 6788 حتدددلل...       -1   \n",
       "997                                               رزمی        1   \n",
       "998                                قوقل بروز رسانی شده       -1   \n",
       "999                                           hyper 24       -1   \n",
       "\n",
       "                                        token_type_ids  \n",
       "0                       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1                       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2                       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3                       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4                       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "..                                                 ...  \n",
       "995  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "996  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "997  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "998  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "999  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# dataset_handler.df.loc[dataset_handler.df[\"similar\"] == 0]\n",
    "print(dataset_handler.get_dataset())\n",
    "dataset_handler.df\n",
    "pd.DataFrame(dataset_handler.get_dataset()[\"train\"][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17516 samples, test on 4380 samples\n",
      "A\n",
      "----------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4e72d9b4154491ac907e41fe1cf49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[Epoch 1/3]', max=548.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 5])\n",
      "torch.Size([32, 1, 5])\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mohsen\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-217c300ed341>\", line 5, in <module>\n",
      "    trainer.train()\n",
      "  File \"F:\\Programming\\DNN\\Tapsell\\Task\\sponsored-search\\src\\Trainer.py\", line 34, in train\n",
      "    outputs = self.query_ad_coordinator(*batch_inputs)\n",
      "  File \"C:\\Users\\Mohsen\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"F:\\Programming\\DNN\\Tapsell\\Task\\sponsored-search\\src\\QueryAdCoordinator.py\", line 14, in forward\n",
      "    x2_repr = self.representation_builder(x2, attention_mask2)\n",
      "  File \"C:\\Users\\Mohsen\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"F:\\Programming\\DNN\\Tapsell\\Task\\sponsored-search\\src\\RepresentationBuilder.py\", line 14, in forward\n",
      "    out = self.pooling_module(out, attention_mask)\n",
      "  File \"C:\\Users\\Mohsen\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"F:\\Programming\\DNN\\Tapsell\\Task\\sponsored-search\\src\\SpanPooling.py\", line 40, in forward\n",
      "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
      "RuntimeError: The expanded size of the tensor (1) must match the existing size (10) at non-singleton dimension 1.  Target sizes: [32, 1, 5].  Tensor sizes: [32, 10, 1]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mohsen\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mohsen\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Mohsen\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Mohsen\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Mohsen\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Mohsen\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Mohsen\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Mohsen\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Mohsen\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Mohsen\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Mohsen\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (10) at non-singleton dimension 1.  Target sizes: [32, 1, 5].  Tensor sizes: [32, 10, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import Trainer\n",
    "reload(Trainer)\n",
    "\n",
    "trainer = Trainer.Trainer(embedding_dim=5, dataset_handler=dataset_handler)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Siamese(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Siamese, self).__init__()\n",
    "        self.representation_builder = torch.nn.Sequential(\n",
    "            RepresentationBuilder(vocab_size, embedding_dim),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.loss = torch.nn.CosineEmbeddingLoss(margin=0)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1_repr = self.representation_builder(x1)\n",
    "        x2_repr = self.representation_builder(x2)\n",
    "        print(x1_repr)\n",
    "        print(x2_repr)\n",
    "        print(self.loss(x1_repr, x2_repr, target=torch.tensor([-1, 1])))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.DatasetHandler import DatasetHandler\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, vocab_size, embedding_dim, dataset_handler: DatasetHandler):\n",
    "        self.siamese = Siamese(vocab_size, embedding_dim)\n",
    "    \n",
    "    def train(self):\n",
    "        self.siamese(torch.tensor([[1], [0, 0, 0, 0]]), torch.tensor([[1, 2, 3, 3], [9, 9, 9, 9]]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_handler.df[:100]\n",
    "# dataset_handler.dataset\n",
    "# d = dataset_handler.df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dd = dataset_handler.df.sample(frac=0.01)\n",
    "dd.to_pickle(\"small.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
