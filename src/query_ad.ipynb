{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def count_unique_words(corpus):\n",
    "    words_freq = dict()\n",
    "    for sentence in tqdm(corpus):\n",
    "        # print(sentence)\n",
    "        for word in str(sentence).split():\n",
    "            if word not in words_freq:\n",
    "                words_freq[word] = 1\n",
    "            else:\n",
    "                words_freq[word] += 1\n",
    "    return words_freq\n",
    "    \n",
    "words_freq = count_unique_words(df[\"queryText\"])\n",
    "len(words_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Labeling Packages', max=65689152.0, style=ProgressStyle(d…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ec17e11686a4bdf9af3a5c39aec1c56"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class DatasetHandler:\n",
    "    def __init__(self, file_address):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
    "        self.df = pd.read_csv(file_address) if \"csv\" in file_address else pd.read_pickle(file_address)\n",
    "        self.df[\"similar\"] = 1\n",
    "        self.package_to_id, self.id_to_package = self.label_packages(self.df[\"packageName\"], start_id=len(tokenizer.get_vocab()))\n",
    "        \n",
    "    def label_packages(self, packages: list, start_id=0):\n",
    "        package_to_id = dict()\n",
    "        id_to_package = dict()\n",
    "        id_counter = start_id\n",
    "        for package in tqdm(packages, desc=\"Labeling Packages\"):\n",
    "            if package not in package_to_id:\n",
    "                package_to_id[package] = id_counter\n",
    "                id_to_package[id_counter] = package\n",
    "                id_counter += 1\n",
    "        return package_to_id, id_to_package\n",
    "    \n",
    "    def save_negative_sampled_dataset(self, neg_to_pos_ratio:int=4, output_name=\"neg_sampled_data.pkl\", seed=0):\n",
    "        random.seed(seed)\n",
    "        negative_rows = []\n",
    "        random_choices = list(self.package_to_id.keys())\n",
    "        for query_text, package_name in tqdm(zip(self.df[\"queryText\"], self.df[\"packageName\"]), total=len(self.df[\"queryText\"])):\n",
    "            for _ in range(neg_to_pos_ratio):\n",
    "                random_package = random.choice(random_choices)\n",
    "                while random_package == package_name:\n",
    "                    random_package = random.choice(random_choices)\n",
    "                negative_rows.append({'queryText': query_text, \"packageName\": random_package, \"similar\": 0})\n",
    "        neg_df = pd.DataFrame(negative_rows)\n",
    "        new_df = pd.concat([self.df, neg_df], ignore_index=True)\n",
    "        new_df.to_pickle(\"data/neg_sampled_data.pkl\")\n",
    "        return new_df\n",
    "\n",
    "# dataset_handler = DatasetHandler(\"data/SA_history_clicks_of_98.csv\")\n",
    "dataset_handler = DatasetHandler(\"../data/neg_sampled_data5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df = dataset_handler.save_negative_sampled_dataset(neg_to_pos_ratio=5)\n",
    "# new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                       queryText                        packageName  similar\n0                         توشمال      com.example.masood.yocheneapp        1\n1                           rush                  com.ketchapp.rush        1\n2                         شب چله              yalda.ir.kr.si.ma.usn        1\n3                            عشق            com.roman.jadogareeshgh        1\n4                          کلابی                    ir.mmdali.cluby        1\n...                          ...                                ...      ...\n65689147  کاهتهتخنتالفل 644 علیر           com.OmidStudio.Monster17        1\n65689148  کاهتهتخنتالفل 644 علیر  com.zeinabbanoo16.pareshehaiajani        1\n65689149  کاهتهتخنتالفل 644 علیر                    app.kalagsm.com        1\n65689150  کاهتهتخنتالفل 644 علیر     ir.hassanmansouri.mohsenyegane        1\n65689151  کاهتهتخنتالفل 644 علیر                          ir.iloveu        1\n\n[65689152 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>queryText</th>\n      <th>packageName</th>\n      <th>similar</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>توشمال</td>\n      <td>com.example.masood.yocheneapp</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>rush</td>\n      <td>com.ketchapp.rush</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>شب چله</td>\n      <td>yalda.ir.kr.si.ma.usn</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>عشق</td>\n      <td>com.roman.jadogareeshgh</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>کلابی</td>\n      <td>ir.mmdali.cluby</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>65689147</td>\n      <td>کاهتهتخنتالفل 644 علیر</td>\n      <td>com.OmidStudio.Monster17</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>65689148</td>\n      <td>کاهتهتخنتالفل 644 علیر</td>\n      <td>com.zeinabbanoo16.pareshehaiajani</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>65689149</td>\n      <td>کاهتهتخنتالفل 644 علیر</td>\n      <td>app.kalagsm.com</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>65689150</td>\n      <td>کاهتهتخنتالفل 644 علیر</td>\n      <td>ir.hassanmansouri.mohsenyegane</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>65689151</td>\n      <td>کاهتهتخنتالفل 644 علیر</td>\n      <td>ir.iloveu</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>65689152 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "dataset_handler.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.SpanPooling import *\n",
    "\n",
    "class RepresentationBuilder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=300):\n",
    "        super(RepresentationBuilder, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        self.pooling_module = get_pooling_module(\"avg\")\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.embedding(input_ids)\n",
    "        print(out)\n",
    "        out = self.pooling_module(out, attention_mask)\n",
    "        return out\n",
    "\n",
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Siamese(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Siamese, self).__init__()\n",
    "        self.representation_builder = torch.nn.Sequential(\n",
    "            RepresentationBuilder(vocab_size, embedding_dim),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.loss = torch.nn.CosineEmbeddingLoss(margin=0)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1_repr = self.representation_builder(x1)\n",
    "        x2_repr = self.representation_builder(x2)\n",
    "        print(x1_repr)\n",
    "        print(x2_repr)\n",
    "        print(self.loss(x1_repr, x2_repr, target=torch.tensor([-1, 1])))\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        self.siamese = Siamese(vocab_size, embedding_dim)\n",
    "    \n",
    "    def train(self):\n",
    "        self.siamese(torch.tensor([[1], [0, 0, 0, 0]]), torch.tensor([[1, 2, 3, 3], [9, 9, 9, 9]]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-f2b02eb5f727>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-79d8b57e97d9>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msiamese\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 1 at dim 1 (got 4)"
     ],
     "ename": "ValueError",
     "evalue": "expected sequence of length 1 at dim 1 (got 4)",
     "output_type": "error"
    }
   ],
   "source": [
    "trainer = Trainer(vocab_size=10, embedding_dim=5)\n",
    "trainer.train()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}