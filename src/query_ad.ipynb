{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df = dataset_handler.save_negative_sampled_dataset(neg_to_pos_ratio=5)\n",
    "# new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.SpanPooling import *\n",
    "\n",
    "class RepresentationBuilder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=300):\n",
    "        super(RepresentationBuilder, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        self.pooling_module = get_pooling_module(\"avg\")\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.embedding(input_ids)\n",
    "        print(out)\n",
    "        out = self.pooling_module(out, attention_mask)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Siamese(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Siamese, self).__init__()\n",
    "        self.representation_builder = torch.nn.Sequential(\n",
    "            RepresentationBuilder(vocab_size, embedding_dim),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.loss = torch.nn.CosineEmbeddingLoss(margin=0)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1_repr = self.representation_builder(x1)\n",
    "        x2_repr = self.representation_builder(x2)\n",
    "        print(x1_repr)\n",
    "        print(x2_repr)\n",
    "        print(self.loss(x1_repr, x2_repr, target=torch.tensor([-1, 1])))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.DatasetHandler import DatasetHandler\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, vocab_size, embedding_dim, dataset_handler: DatasetHandler):\n",
    "        self.siamese = Siamese(vocab_size, embedding_dim)\n",
    "    \n",
    "    def train(self):\n",
    "        self.siamese(torch.tensor([[1], [0, 0, 0, 0]]), torch.tensor([[1, 2, 3, 3], [9, 9, 9, 9]]))\n",
    "        \n",
    "    def predict_from_query(self, queryText):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Reading input file...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0242c88226a040639c28e70d9253d712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Labeling Packages', max=93001.0, style=ProgressStyle(descâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating dataset...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from src.DatasetHandler import DatasetHandler\n",
    "# dataset_handler = DatasetHandler(\"data/SA_history_clicks_of_98.csv\")\n",
    "dataset_handler = DatasetHandler(\"../data/small.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "547410"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset_handler.df[:100]\n",
    "# dataset_handler.dataset\n",
    "# d = dataset_handler.df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dd = dataset_handler.df.sample(frac=0.01)\n",
    "dd.to_pickle(\"small.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(vocab_size=10, embedding_dim=5, dataset_handler=dataset_handler)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
